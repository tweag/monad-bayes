{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"docs/","title":"Welcome to Monad-Bayes","text":"<p>Monad-Bayes is a library for probabilistic programming written in Haskell.</p> <p>Define distributions as programs</p> <p>Perform inference with a variety of standard methods defined compositionally</p> <p>Integrate with Haskell code like this because Monad-Bayes is just a library, not a separate language</p>"},{"location":"docs/#example","title":"Example","text":"<pre><code>model :: Distribution Double\nmodel = do\n     x &lt;- bernoulli 0.5\n     normal (if x then (-3) else 3) 1\n\nimage :: Distribution Plot\nimage = fmap (plot . histogram 200) (replicateM 100000 model)\n\nsampler image\n</code></pre> <p>The program <code>model</code> is a mixture of Gaussians. Its type <code>Distribution Double</code> represents a distribution over reals.  <code>image</code> is a program too: as its type shows, it is a distribution over plots. In particular, plots that arise from forming a 200 bin histogram out of 100000 independent identically distributed (iid) draws from <code>model</code>.  To sample from <code>image</code>, we simply write <code>sampler image</code>, with the result shown below:</p>"},{"location":"docs/examples/","title":"Example Gallery","text":""},{"location":"docs/examples/#histograms","title":"Histograms","text":""},{"location":"docs/examples/#json-with-lens","title":"JSON (with <code>lens</code>)","text":""},{"location":"docs/examples/#diagrams","title":"Diagrams","text":""},{"location":"docs/examples/#probabilistic-parsing","title":"Probabilistic Parsing","text":""},{"location":"docs/examples/#streams-with-pipes","title":"Streams (with <code>pipes</code>)","text":""},{"location":"docs/examples/#ising-models","title":"Ising models","text":""},{"location":"docs/examples/#physics","title":"Physics","text":""},{"location":"docs/probprog/","title":"User Guide","text":"<p>Probabilistic programming is all about being able to write probabilistic models as programs. For instance, here is a Bayesian linear regression model, which we would write equationally as:</p> \\[ \\beta \\sim \\operatorname{normal}(0, 2) \\] \\[ \\alpha \\sim \\operatorname{normal}(0, 2) \\] \\[ \\sigma^2 \\sim \\operatorname{gamma}(4, 4) \\] \\[ \\epsilon_{n} \\sim \\operatorname{normal}(0, \\sigma) \\] \\[ y_{n}=\\alpha+\\beta x_{n}+\\epsilon_{n}  \\] <p>but in code as:</p> <pre><code>paramPriorRegression :: Distribution (Double, Double, Double)\nparamPriorRegression = do\n    slope &lt;- normal 0 2\n    intercept &lt;- normal 0 2\n    noise &lt;- gamma 4 4\n    return (slope, intercept, noise)\n\nregression :: Kernel [(Double, Double)] (Double, Double, Double)\nregression xsys = do\n    (slope, intercept, noise) &lt;- paramPriorRegression\n    forM_ xsys \\(x, y) -&gt; factor $ normalPdf (slope * x + intercept) (sqrt noise) y\n    return (slope, intercept, noise)\n</code></pre> <p><code>regression</code> takes observations (a list of pairs of x and y values), and using the prior expressed by <code>paramPriorRegression</code>, returns the posterior conditioned on the observations.</p> <p>This is the model. To perform inference , suppose we have a data set <code>xsys</code> like:</p>  <p>To run the model</p> <pre><code>mhRunsRegression = sampler \n  $ mcmc MCMCConfig \n      {numMCMCSteps = 1500, \n      proposal = SingleSiteMH, \n      numBurnIn = 500} \n  (regression xsys)\n</code></pre> <p>This yields 1000 samples from an MCMC walk using an MH kernel. <code>mh n</code> produces a distribution over chains of length <code>n</code>, along with the probability of that chain. Sampling a chain and plotting its final state gives:</p>  <p>Monad-bayes provides a variety of MCMC and SMC methods, and methods arising from the composition of the two. </p>"},{"location":"docs/probprog/#resources","title":"Resources","text":"<p>Other probabilistic programming languages with fairly similar APIs include WebPPL and Gen. This cognitive-science oriented introduction to WebPPL is an excellent resource for learning about probabilistic programming. The tutorials for Gen are also very good, particularly for learning about traces.</p>"},{"location":"docs/probprog/#specifying-distributions","title":"Specifying distributions","text":"<p>A distribution in monad-bayes over a set \\(X\\), is of type:</p> <pre><code>MonadMeasure m =&gt; m X\n</code></pre> <p>For beginner friendliness, a synonym <code>type Measure a = forall m . MonadDistribution m =&gt; m a</code> is provided (as well as <code>Distribution</code> shown above, for normalized distributions, and <code>Kernel</code> for functions into distributions).</p> <p>Monad-bayes provides standard distributions, such as</p> <pre><code>random :: Distribution Double\n</code></pre> <p>which is distributed uniformly over \\([0,1]\\).</p> <p>The full set is listed at https://hackage.haskell.org/package/monad-bayes-0.1.1.0/docs/Control-Monad-Bayes-Class.html</p> <p>Note that these primitives already allows us to construct quite exotic distributions, like the uniform distribution over <code>(+) :: Int -&gt; Int -&gt; Int</code> and <code>(-) :: Int -&gt; Int -&gt; Int</code>:</p> <pre><code>distributionOverFunctions :: Distribution (Int -&gt; Int -&gt; Int)\ndistributionOverFunctions = uniformD [(+), (-)]\n</code></pre>"},{"location":"docs/probprog/#constructing-distributions-as-programs","title":"Constructing distributions as programs","text":"<p>monad-bayes also lets us construct new distributions out of these. <code>MonadMeasure m</code> implies <code>Monad m</code> and in turn <code>Functor m</code>, so we can do the following:</p> <pre><code>fmap (&gt; 0.5) random :: MonadMeasure m =&gt; m Bool\n</code></pre> <p>This is the uniform distribution over \\((0.5, 1]\\).</p> <p>As an important special case, if <code>x :: MonadMeasure m =&gt; m (a,b)</code> is a joint distribution over two variables, then <code>fmap fst a :: MonadMeasure m =&gt; m a</code> marginalizes out the second variable. That is to say, <code>fmap fst a</code> is the distribution \\(p(a)\\), where \\(p(a) = \\int_b p(a,b)\\).</p> <p>The above example use only the functor instance for <code>m</code>, but we also have the monad instance, as used in:</p> <pre><code>example :: MonadMeasure m =&gt; m Double\nexample = bernoulli 0.5 &gt;&gt;= (\\x -&gt; if x then random else normal 0 1)\n</code></pre> <p>It's easiest to understand this distribution as a probabilistic program: it's the distribution you get by first sampling from <code>bernoulli 0.5</code>, then checking the result. If the result is <code>True</code>, then sample from <code>random</code>, else from <code>normal 0 1</code>. As a distribution, this has a PDF:</p> \\[ f(x) = 1[0\\leq x \\leq 1]*0.5  + \\mathcal{N}(0,1)(x)*0.5   \\] <p>Equivalently, we could write this in do-notation as:</p> <pre><code>example :: MonadMeasure m =&gt; m Double\nexample = do\n  bool &lt;- bernoulli 0.5\n  if bool then random else normal 0 1\n</code></pre> <p>A technical note: it is often tempting to read the line <code>bool &lt;- bernoulli 0.5</code> as saying \"take a sample from <code>bernoulli 0.5</code>. But although we'll see below that <code>example</code> can be interpreted as a sampler, there are many other interpretations, not least as a mathematical specification of a particular distribution.</p> <p>That said, it is often useful to think of probabilistic programs as specifying distributions over program executation traces. For example, one trace of <code>example</code> as defined above is (informally): <code>{bernoulli 0.5 : True, random : 0.7}</code>.</p>"},{"location":"docs/probprog/#hard-and-soft-conditioning","title":"Hard and soft conditioning","text":"<p>monad-bayes provides a function <code>score :: MonadMeasure m =&gt; Log Double -&gt; m ()</code>. (Note: <code>Log Double</code> is a wrapper for <code>Double</code> which stores doubles as their logarithm, and does multiplication by addition of logarithms.)</p> <pre><code>example :: MonadMeasure m =&gt; m Double\nexample = do\n  bool &lt;- bernoulli 0.5\n  number &lt;- if bool then random else normal 0 1\n  score number \n  return bool\n</code></pre> <p>It's easiest to understand this in terms of the \"program execution trace\" perspective described above. What the score statement does is to multiple every trace by the value of <code>number</code> in that particular trace.</p> <p><code>condition</code> in then defined as follows:</p> <p><pre><code>condition :: MonadMeasure m =&gt; Bool -&gt; m ()\ncondition b = score $ if b then 1 else 0\n</code></pre> So <code>condition b</code> throws away every trace in which <code>b</code> is False, and keeps all traces in which <code>b</code> is True. For example:</p> <pre><code>example :: MonadMeasure m =&gt; m Int\nexample = do\n  n &lt;- poisson 0.5\n  condition (n%2 == 0)\n  return n\n</code></pre> <p>This describes a Poisson distribution in which all even values of the random variable are marginalized out.</p>"},{"location":"docs/probprog/#inference-methods","title":"Inference methods","text":"<p>To quote this page, \"marginal inference (or just inference) is the process of reifying the distribution on return values implicitly represented by a stochastic computation.\". That is, a probabilistic program (stochastic computation) is an abstract object and inference transforms it into something concrete, like a histogram, a list of samples, or parameters of a known distribution.</p> <p>All inference methods in monad-bayes work with all distributions. The only exception is that exact inference only works with discrete distributions and will throw a runtime error on continuous distributions.</p> <p>The challenge of inference is that most distributions that are of interest are not as simple as <code>sprinkler</code>. They could have continuous random variables, a huge number of them, or even a number of them that is itself random. They could involve a series of observations, interspersed with other sources of randomness.</p> <p>Designing a language in which you can specify arbitrarily complex (computable) distributions as probabilistic programs turns out to be a largely solved problem. The tools given about are sufficient for that. </p> <p>The hard part is designing a language where you can specify how you want to do inference, because sophisticated, often approximate, inference methods are almost always necessary for the models involved in solving real world problems.</p> <p>Two of the large classes of inference methods are sampling based methods and gradient based methods. The latter only apply to continuous probability distributions, and are not the focus of monad-bayes.</p>"},{"location":"docs/probprog/#exact-inference","title":"Exact inference","text":"<pre><code>enumerator :: Ord a =&gt; Enumerator a -&gt; [(a, Double)]\n</code></pre> <p>So <code>enumerator (bernoulli 0.7)</code> gives you</p> <pre><code>[(False,0.3),(True,0.7)]\n</code></pre> <p>This works for distributions with <code>factor</code> statements (i.e. an instance of <code>MonadMeasure</code>), as in:</p> <pre><code>model :: MonadMeasure m =&gt; m Bool\nmodel = do\n  x &lt;- bernoulli 0.5\n  y &lt;- bernoulli 0.3\n  condition (x || y)\n  return x\n\nenumerator model\n\n&gt; [(True,0.7692307692307692),(False,0.23076923076923078)]\n</code></pre> <p>Note: <code>enumerator</code> only works on finite discrete distributions</p> <p>It will run forever on infinite distributions like <code>enumerator (poisson 0.7)</code> and will throw the following runtime error on continuous distributions as in <code>enumerator (normal 0 1)</code>:</p> <p>\"Exception: Infinitely supported random variables not supported in Enumerator\"</p> <p>However, it's totally fine to have the elements of the support themselves be infinite, as in:</p> <pre><code>fmap (\\(ls,p) -&gt; (take 4 ls, p)) $ enumerator $ uniformD [[1..], [2..]]\n</code></pre> <p>which gives</p> <pre><code>[([1,2,3,4],0.5),([2,3,4,5],0.5)]\n</code></pre>"},{"location":"docs/probprog/#near-exact-inference-for-continuous-distributions","title":"Near exact inference for continuous distributions","text":"<p>Monad-Bayes does not currently support exact inference (via symbolic solving) for continuous distributions. However, it does support numerical integration. For example, for the distribution defined by</p> <pre><code>model :: MonadDistribution m =&gt; m Double\nmodel = do\n  var &lt;- gamma 1 1\n  normal 0 (sqrt var)\n</code></pre> <p>you may run <code>probability (0, 1000) model</code> to obtain the probability in the range <code>(0,1000)</code>. As expected, this should be roughly \\(0.5\\), since the PDF of <code>model</code> is symmetric around \\(0\\).</p> <p>You can also try <code>expectation model</code>, <code>variance model</code>, <code>momentGeneratingFunction model n</code> or <code>cdf model n</code>. </p> <p>If the model has factor statements, as in</p> <pre><code>model :: MonadMeasure m =&gt; m Double\nmodel = do\n  var &lt;- gamma 1 1\n  n &lt;- normal 0 (sqrt var)\n  condition (n &gt; 0)\n  return var\n</code></pre> <p>we must first <code>normalize</code> the model, as in <code>probability (0, 0.1) (normalize model)</code>.</p>"},{"location":"docs/probprog/#independent-forward-sampling","title":"Independent forward sampling","text":"<p>For any probabilistic program <code>p</code> without any <code>condition</code> or <code>factor</code> statements, we may do <code>sampler p</code> or <code>sampleIOfixed p</code> (to run with a fixed seed) to obtain a sample in an ancestral fashion. For example, consider:</p> <pre><code>example = do\n  x &lt;- bernoulli 0.5\n  if x then normal 0 1 else normal 1 2\n</code></pre> <p><code>sampler example</code> will produce a sample from a Bernoulli distribution with \\(p=0.5\\), and if it is \\(True\\), return a sample from a standard normal, else from a normal with mean 1 and std 2.</p> <p><code>(replicateM n . sampler) example</code> will produce a list of <code>n</code> independent samples. However, it is recommended to instead do <code>(sampler . replicateM n) example</code>, which will create a new model (<code>replicateM n example</code>) consisting of <code>n</code> independent draws from <code>example</code>. </p> <p>Because <code>sampler example</code> is totally pure, it is parallelizable. </p> <p>Monad-bayes gives the user freedom in the random number generator of the sampler: use <code>sampleWith</code> for full control.</p>"},{"location":"docs/probprog/#independent-weighted-sampling","title":"Independent weighted sampling","text":"<p>To perform weighted sampling, use:</p> <pre><code>(sampler . weighted) :: Weighted SamplerIO a -&gt; IO (a, Log Double)\n</code></pre> <p><code>Weighted SamplerIO</code> is an instance of <code>MonadMeasure</code>, so we can apply this to any distribution. For example, suppose we have the distribution:</p> <pre><code>example :: MonadMeasure m =&gt; m Bool\nexample = do\n  x &lt;- bernoulli 0.5\n  condition x\n  return x\n</code></pre> <p>Then:</p> <pre><code>run :: IO (Bool, Log Double)\nrun = (sampler . weighted) example\n</code></pre> <p>is an IO operation which when run, will display either <code>(False, 0.0)</code> or <code>(True, 1.0)</code></p>"},{"location":"docs/probprog/#lazy-sampling","title":"Lazy sampling","text":"<p>If you want to forward sample from an infinite program, just as a distribution over infinite lists, you can use monad-bayes's lazy sampler, which is based on LazyPPL. For example,</p> <pre><code>import qualified Control.Monad.Bayes.Sampler.Lazy as Lazy\n\nexample :: MonadDistribution m =&gt; m [Double]\nexample = do \n  x &lt;- random\n  fmap (x:) example\n\ninfiniteList &lt;- Lazy.sampler example\ntake 4 infiniteList\n</code></pre> <p>To perform weighted sampling, use <code>lwis</code> from <code>Control.Monad.Bayes.Inference.Lazy.WIS</code> as in <code>lwis 10 example</code>. This takes 10 weighted samples, and produces an infinite stream of samples, regarding those 10 as an empirical distribution. </p> <p>LazyPPL's <code>mh</code> implementation is also available.</p>"},{"location":"docs/probprog/#markov-chain-monte-carlo","title":"Markov Chain Monte Carlo","text":"<p>There are several versions of metropolis hastings MCMC defined in monad-bayes. The standard version is found in <code>Control.Monad.Bayes.Inference.MCMC</code>. You can use it as follows:</p> <pre><code>(sampler . mcmc (MCMCConfig {\n  numMCMCSteps = 10, \n  numBurnIn = 5, \n  proposal = SingleSiteMH})) :: Traced (Weighted SamplerIO) a -&gt; IO [a]\n</code></pre> <p>As you can see, <code>mcmc</code> takes a <code>MCMCConfig</code> object, which is where you specify the number of steps in the MCMC chain, and the number of burn in steps. <code>SingleSiteMH</code> refers to the proposal used in the chain.</p> <p><code>Traced (Weighted SamplerIO)</code> is an instance of <code>MonadMeasure</code>, so we can apply this to any distribution. For instance:</p> <pre><code>example :: MonadMeasure m =&gt; m Bool\nexample = do\n  x &lt;- bernoulli 0.5\n  condition x\n  return x\n</code></pre> <p>Then </p> <pre><code>run :: IO [Bool]\nrun = (sampler . mcmc (MCMCConfig {\n  numMCMCSteps = 10, \n  numBurnIn = 5, \n  proposal = SingleSiteMH})) example\n</code></pre> <p>produces \\(5\\) unbiased samples from the posterior, by using single-site trace MCMC with the Metropolis-Hastings (MH) method. This means that the random walk is over execution traces of the probabilistic program, and the proposal distribution modifies a single random variable as a time, and then uses MH for the accept-reject criterion. For example, from the above you'd get:</p> <pre><code>[True,True,True,True,True]\n</code></pre> <p>The final element of the chain is the head of the list, so you can drop samples from the end of the list for burn-in.</p>"},{"location":"docs/probprog/#streaming-mcmc","title":"Streaming MCMC","text":"<p>You can also run <code>MCMC</code> using <code>mcmcP</code>. This creates an infinite chain, expressed as a stream or using the corresponding type from the <code>pipes</code> library, a <code>Producer</code>. This is a very natural representation of a random walk in Haskell.</p> <p>You can run this with a terminal user interface (TUI) by doing e.g.</p> <pre><code>tui 0 random noVisual\n</code></pre>"},{"location":"docs/probprog/#sequential-monte-carlo-particle-filtering","title":"Sequential Monte Carlo (Particle Filtering)","text":"<p>Run SMC with two resampling steps and two particles as follows, given a model <code>m</code>:</p> <pre><code>output = \n  sampler $ \n  population $ \n  smc (SMCConfig \n    {numSteps = 2, \n    numParticles = 2, \n    resampler = resampleMultinomial} )\n  m\n</code></pre>"},{"location":"docs/probprog/#interoperating-with-other-haskell-code","title":"Interoperating with other Haskell code","text":"<p>Probabilistic programs in monad-bayes are Haskell programs. This contrasts to many probabilistic programming languages, which are deeply embedded and cannot smoothly interact with their host language. </p> <p>For example, we can use ordinary monadic combinators, as in:</p> <pre><code>example = do\n  x &lt;- bernoulli 0.5\n  when x (score 0.8)\n  return x\n</code></pre> <p>or </p> <pre><code>example = whileM (bernoulli 0.99) (normal 0 1)\n</code></pre> <p>You may write distributions over artibrary types. For example, rather than drawing a sample from a distribution and then using the sample to construct a histogram or a plot, you can directly define a distribution over histograms or plots, and sample from that.</p> <p>You can have distributions over arbitrary data structures, such as trees, JSONs, databases, and so on. You can use <code>MonadMeasure m =&gt; m</code> as the monad in libraries which are parametric in a monad, such as <code>megaparsec</code> or <code>pipes</code>.</p>"},{"location":"docs/probprog/#tips-on-writing-good-probabilistic-programs","title":"Tips on writing good probabilistic programs","text":"<p>There are many ways to specify the same distribution, and some will lend themselves more readily to efficient inference than others. For instance,</p> <pre><code>mixture1 point = do\n    cluster &lt;- uniformD [1,5]\n    prediction &lt;- normal cluster 1\n    condition (prediction == point )\n    return cluster\n</code></pre> <p>is a piece of code to infer whether an observed point was generated from a Gaussian of mean \\(1\\) or \\(5\\). That is, <code>mixture1</code> is a conditional Bernoulli distribution over the mean given an observation. You're not going to be able to do much with <code>mixture1</code> though. Exact inference is impossible because of the sample from the normal, and as for sampling, there is zero probability of sampling the normal to exactly match the observed point, which is what the <code>condition</code> requires.</p> <p>However, the same conditional distribution is represented by </p> <pre><code>mixture2 point = do\n    cluster &lt;- uniformD [1,5]\n    factor (normalPdf cluster 1 point)\n    return cluster\n</code></pre> <p>This version, while denotationally identical (i.e. representing the same mathematical object), is perfectly amenable to exact inference:</p> <pre><code>enumerator $ mixture2 2\n</code></pre> <p>yields</p> <pre><code>[(1.0, 0.98...), (5.0, 0.017...)]\n</code></pre> <p>as well as sampling methods. </p> <p>The local lesson here is that you shouldn't <code>condition</code> on samples from a continuous distribution and expect a sampling based inference method to work. But the more general lesson is that you aren't exempted from thinking about inference when specifying your model. Alas.</p> <p>As a second example of this general point, consider:</p> <pre><code>allAtOnce = do\n    x &lt;- bernoulli 0.5\n    y &lt;- bernoulli 0.5\n    condition (x &amp;&amp; y)\n    return (x &amp;&amp; y)\n</code></pre> <p>and</p> <pre><code>incremental = do\n    x &lt;- bernoulli 0.5\n    condition x\n    y &lt;- bernoulli 0.5\n    condition y\n    return (x &amp;&amp; y)\n</code></pre> <p>Like in the previous example, <code>allAtOnce</code> and <code>incremental</code> denote the same distribution, namely <code>[(True, 1.0), (False, 0.0)]</code>. However, any inference algorithm for <code>allAtOnce</code> will have to explore all 4 possible variable assignments (<code>[(True,True), (True, False), (False, True), (False, False)]</code>). Meanwhile, <code>incremental</code> opens the possibility for inference algorithms to first determine the value of <code>x</code> and then of <code>y</code>.</p> <p>In this example, the performance difference is negligible, but it's easy to extend this to models where it's the difference between something tractable and something intractable. </p>"},{"location":"docs/probprog/#api-docs","title":"API docs","text":"<p>For API docs in the normal Haskell style, see hackage.</p>"},{"location":"docs/probprog/#monad-bayes-vs-other-libraries","title":"Monad-Bayes vs other libraries","text":"<p>Monad-bayes is a universal probabilistic programming system, in the sense that you can express any computable distribution. In this respect it differs from Stan, which focuses instead on handling inference on an important subset well.</p> <p>There is a variety of universal probabilistic programming libraries and/or languages, which include WebPPL, Gen, Pyro and Edward.</p> <p>What other approaches have that Monad-Bayes lacks:</p> <p>A lot of engineering work has been put into the above libraries and languages to make them practical for real-world problems. While monad-bayes' core is very nice, it doesn't come with a lot of the batteries you might want. (The author's PhD thesis contains this relevant paragraph: \"our library implements basic versions of advanced sampling algorithms. However, their successful application in practice requires incorporating established heuristics, such as: adaptive proposal distributions, controlling resampling with effective sample size, tuning rejuvenation kernels based on population in SMC2, and so on.\")</p> <p>What Monad-Bayes has that is unique: </p> <p>Monad-Bayes is just a library, unlike almost all other PPLs, which are separate languages written inside another language. As such, probabilistic programs in monad-bayes are first class programs in Haskell with no new special syntax or keywords. This allows all of Haskell's expressive power to be brought to bear. You can write distributions over any datatype (lists, trees, functions, histograms, JSON files, graphs, diagrams, etc). You can use powerful libraries like <code>pipes</code>, <code>lens</code> and <code>Parsec</code>. Everything is pure. Everything is strongly typed. You can make use of laziness.</p> <p>Models are monadic and inference is modular. Complex inference algorithms like RMSMC or PMMH are built out of simple composable pieces, and so are expressable extraordinarily simply.</p>"},{"location":"docs/tutorials/","title":"Tutorials","text":""},{"location":"docs/tutorials/#introduction-to-monad-bayes","title":"Introduction to Monad-Bayes","text":""},{"location":"docs/tutorials/#sampling-from-a-distribution","title":"Sampling from a distribution","text":""},{"location":"docs/tutorials/#bayesian-models","title":"Bayesian models","text":""},{"location":"docs/tutorials/#markov-chain-monte-carlo","title":"Markov Chain Monte Carlo","text":""},{"location":"docs/tutorials/#sequential-monte-carlo","title":"Sequential Monte Carlo","text":""},{"location":"docs/tutorials/#lazy-sampling","title":"Lazy Sampling","text":""},{"location":"docs/tutorials/#advanced-inference-methods","title":"Advanced Inference Methods","text":""},{"location":"docs/usage/","title":"Implementation guide","text":"<p>This document assumes the reader is familiar with the basics of Bayesian probability theory, basic Haskell (the syntax, the type system, do-notation, monad transformers), and how to specify distributions in monad-bayes (see the docs)</p> <p>That's enough to understand the core ideas, but for the more advanced content, you'll also want to feel comfortable enough with Haskell's type system that free monads, free monad transformers, and coroutines aren't a barrier to entry. And of course, to understand how inference methods like MCMC and SMC are implemented, it doesn't hurt to understand how they work in a statistical sense.</p>"},{"location":"docs/usage/#references","title":"References","text":"<p>Monad-Bayes is the codebase accompanying the theory of probabilistic programming described in this paper.</p>"},{"location":"docs/usage/#the-core-typeclasses","title":"The core typeclasses","text":"<p>The library relies on two core typeclasses <code>MonadDistribution</code> and <code>MonadFactor</code>. <code>MonadMeasure</code> is simply the union of the two, that is:</p> <pre><code>(MonadDistribution m, MonadFactor m) =&gt; MonadMeasure m\n</code></pre> <p>You can find these in <code>Control.Monad.Bayes.Class</code>. </p>"},{"location":"docs/usage/#monaddistribution","title":"MonadDistribution","text":"<p>Here is <code>MonadDistribution</code>:</p> <pre><code>class Monad m =&gt; MonadDistribution m where\n  random :: m Double\n</code></pre> <p>This one method, <code>random</code>, represents a uniform distribution over \\([0,1]\\). (<code>MonadDistribution</code> actually has a few other distributions, but that's not essential.)</p> <p>What comes next is clever: you can define any other distribution you like in terms of <code>random</code>. As an example:</p> <pre><code>bernoulli :: MonadDistribution m =&gt; m Bool\nbernoulli p = fmap (&lt; p) random\n</code></pre> <p>That one is pretty simple. As a more complex example, here's how a normal distribution is defined:</p> <pre><code>normal m s = fmap (quantile (normalDistr m s)) random\n</code></pre> <p><code>normalDistr</code> comes from a separate library <code>Statistics.Distribution.Normal</code> and <code>quantile (normalDistr m s) :: Double -&gt; Double</code> is the inverse CDF of the normal, a deterministic function.</p> <p>Again, to emphasize: all of our randomness can be reduced to draws from a uniform distribution over the interval \\([0,1]\\). </p> <p>So we now have a way of constructing distributions in a monadic fashion. As a simple example:</p> <pre><code>example :: MonadDistribution m =&gt; m Double\nexample = do\n    x &lt;- random\n    y &lt;- uniform 0 x\n    return (x + y &gt; 1.5)\n</code></pre> <p>Think of this as the procedure of first sampling uniformly from \\([0,1]\\), then from \\([0,x]\\), and then returning the Boolean \\(x + y &gt; 1.5\\). More precisely, this is the marginal probability of \\(x + y &gt; 1.5\\). </p> <p>Technical note: <code>MonadDistribution</code> actually contains a number of other distributions beyond <code>random</code>, which by default are defined in terms of <code>random</code>, but allow for different definitions when desired. For example, <code>Sampler</code> (an instance of <code>MonadDistribution</code> in Control.Monad.Sampler) defines <code>normal</code> and other distributions independently of <code>random</code>.</p>"},{"location":"docs/usage/#monadfactor","title":"MonadFactor","text":"<p>Here's <code>MonadFactor</code>. </p> <pre><code>class Monad m =&gt; MonadFactor m where\n  score :: Log Double -&gt; m ()\n</code></pre> <p><code>Log Double</code> is defined in <code>Numeric.Log</code>, and is a wrapper for <code>Double</code>s which does multiplication in log-space. It comes with <code>Exp :: a -&gt; Log a</code> and <code>ln :: Log a -&gt; a</code>. This is because we don't want numerical problems when multiplying tiny probabilities, and we want a hassle free typesafe separation of doubles and log-doubles.</p>"},{"location":"docs/usage/#inference-transformers","title":"Inference transformers","text":"<p>Now core idea of monad-bayes is that various monads will be made to be instances of <code>MonadDistribution</code>, <code>MonadFactor</code> or both (i.e. an instance of <code>MonadMeasure</code>), and different inference algorithms will be written using these instances. This separates the specification of the model (which happens abstractly in <code>MonadMeasure</code>) from the inference algorithm, which takes place in on of the concrete instances. The clever part of monad-bayes is that it allows this instances to be constructed in a modular way, using monad transformers. In the paper, these are termed inference transformers to emphasize that it doesn't really matter whether they satisfy the monad laws.</p> <p>For example, to run weighted rejection sampling on a probabilistic program <code>p</code>, we can write <code>(sampler . weighted) p</code>. Here, <code>(sampler . weighted) :: Weighted SamplerIO a -&gt; IO a</code>. So <code>p</code> gets understood as being of type <code>Weighted SamplerIO</code>, a type we'll encounter soon.</p> <p>Some of these transformers are easy to understand (like <code>StateT Double</code>, while others (like the Church transformed Free monad transformer) lie on the more advanced side of things. The following tour of these types goes from easy to hard.</p>"},{"location":"docs/usage/#enumerator","title":"Enumerator","text":"<p>Summary of key info:</p> <ul> <li><code>Enumerator :: Type -&gt; Type</code></li> <li><code>instance MonadDistribution Enumerator</code></li> <li><code>instance MonadFactor Enumerator</code></li> </ul> <p><code>Enumerator</code> is in <code>Control.Monad.Bayes.Enumerator</code>, defined as follows:</p> <pre><code>newtype Enumerator a = \n    Enumerator (WriterT (Product (Log Double)) [] a)\n</code></pre> <p>This merits a little unpacking. First, <code>Product</code> is a wrapper from Data.Monoid which makes the semigroup operator for numbers be multiplication, so that:</p> <pre><code>Product 2 &lt;&gt; Product 3 == Product 6`\n</code></pre> <p>Unpacking the definition of <code>Enumerator a</code>, it is isomorphic to:</p> <pre><code>[(a, (Product (Log Double)))]\n</code></pre> <p>So, a value of type <code>Enumerator Bool</code>, for instance, is a list of pairs of booleans along with a double, like:</p> <pre><code>[(False,0.8914),(True,0.1086)]\n</code></pre> <p>Also in <code>Control.Monad.Bayes.Enumerator</code> is a function <code>enumerator</code>, which has type:</p> <pre><code>enumerator :: Ord a =&gt; Enumerator a -&gt; [(a, Double)]\n</code></pre> <p>We can write <code>enumerator sprinkler</code>. Why is this well typed? The idea is that <code>sprinkler</code> has type <code>forall m. MonadMeasure m =&gt; m Bool</code>, and we instantiate that <code>m</code> as <code>Enumerator</code>.</p> <p>But for this to be well-typed, we need <code>Enumerator</code> to be an instance of <code>MonadMeasure</code>. For that, we need <code>Enumerator</code> to be a <code>MonadDistribution</code>, and a <code>MonadFactor</code>. For that, we need it to be a <code>Monad</code>, and in turn, a <code>Functor</code>. In understanding these instance definition, we'll understand what what <code>Enumerator</code> is doing for us.</p> <p><code>Enumerator</code> is a monad automatically, because <code>WriterT a m</code> is a monad for <code>a</code> a monoid and <code>m</code> a monad. As needed, <code>[]</code> is a monad and <code>Log Double</code> is a monoid. But what does that monad actually do?</p> <p>For instance, if I have a weighted list <code>l</code> like <code>[(False,0.8914),(True,0.1086)]</code> and a function <code>f :: Bool -&gt; Enumerator a</code>, what is <code>l &gt;&gt;= f</code>? It takes each element in <code>l</code>, and passes it through <code>f</code>, to obtain a weighted list of weighted lists. Then it flattens it, by including each element in the inner lists in the resulting list, with the weight of the list multiplied by the weight of the element. As for <code>return x</code>, it gives the singleton list containing the pair of <code>x</code> and the unit of the product monoid, i.e. <code>[(x, 1.0)]</code>. </p> <p>This is the essence of propagating probability forward.</p>  <p>What remains is to define the <code>MonadDistribution</code> and <code>MonadFactor</code> instances:</p> <pre><code>instance MonadDistribution Enumerator where\n  random = error \"Infinitely supported random variables not supported in Enumerator\"\n  bernoulli p = fromList [(True, (Exp . log) p), (False, (Exp . log) (1 - p))]\n</code></pre> <p>The first thing to notice is that <code>random</code> is actually not defined for <code>Enumerator</code>, and consequently, you can't handle any continuous distributions. This makes sense, because you can't represent continuous distributions (whose support is uncountably infinite) as a list of samples.</p> <p>So really <code>Enumerator</code> isn't very general purpose. It's best understood as a didactic tool, rather than a real world inference algorithm. </p> <p>But it can handle discrete distributions. It does this via <code>bernoulli</code> (as well as <code>categorical</code>, which I've omitted). <code>bernoulli p</code> constructs the weighted list corresponding to a <code>bernoulli</code> distribution with parameter <code>p</code>.</p> <p>And the <code>MonadFactor</code> instance: </p> <pre><code>instance MonadFactor Enumerator where\n  score w = fromList [((), w)]\n</code></pre> <p>Finally, <code>enumerator</code> simply unwraps <code>Enumerator</code> to get a list of pairs of values and their weights, and then normalizes them into probabilities. It orders the list, which is why <code>enumerator</code> requires an <code>Ord</code> instance.</p> <p>To see how this all works together, consider:</p> <pre><code>example = do\n  x &lt;- bernoulli 0.5\n  condition x\n  return x\n</code></pre> <p>From the way the <code>MonadDistribution</code> instance for <code>Enumerator</code> is defined, <code>bernoulli 0.5</code> is a list of two pairs: <code>[(True, 0.5), (False, 0.5)]</code>. Using the <code>Monad</code> instance, the next line multiplies each of the masses by a number (<code>0</code> for <code>True</code>, <code>1</code> for <code>False</code>). The final line multiplies both by <code>1.0</code>. And then <code>enumerator</code> normalizes the result. So the ensuing distribution from <code>enumerator example</code> is <code>{True : 1.0}</code>.</p>"},{"location":"docs/usage/#samplerio","title":"SamplerIO","text":"<p>Summary of key info on <code>SamplerIO</code>:</p> <ul> <li><code>SamplerIO :: Type -&gt; Type</code></li> <li><code>instance MonadDistribution SamplerIO</code></li> <li>No instance for <code>MonadFactor</code></li> </ul> <p>Monad-Bayes actually provides a more general constructor:</p> <pre><code>newtype Sampler g m a = Sampler (ReaderT g m a)\n</code></pre> <p><code>SamplerIO</code> just specializes <code>g</code>, which is the random number generator, and <code>m</code>, the IO-handling monad:</p> <pre><code>type SamplerIO = Sampler (IOGenM StdGen) IO\n</code></pre> <p>But you can specialize many other ways (see the <code>random</code> package), depending on your use case.</p> <p>As the names suggest, <code>SamplerIO</code> instantiates an abstract distribution as a sampling procedure. We have</p> <pre><code>instance MonadDistribution (Sampler g m) where\n  random = Sampler (ReaderT uniformDouble01M)\n\n  uniform a b = Sampler (ReaderT $ uniformRM (a, b))\n  normal m s = Sampler (ReaderT (MWC.normal m s))\n  gamma shape scale = Sampler (ReaderT $ MWC.gamma shape scale)\n  beta a b = Sampler (ReaderT $ MWC.beta a b)\n\n  ...\n</code></pre> <p>Were the lines from <code>uniform</code> to <code>beta</code> commented out, they would be instantiated with the defaults defined in terms of <code>random</code> in the <code>MonadDistribution</code> class. The reason they are not is that there are more statistically efficient ways to sample.</p> <p>We can unpack values from <code>SamplerIO a</code> using <code>sampler :: SamperIO a -&gt; IO a</code>. So for example:</p> <pre><code>print =&lt;&lt; sampler random\n</code></pre> <p>will print a sample from <code>random</code>. Similarly for other distributions. </p> <p>But note that <code>SamplerIO</code> only has a <code>MonadDistribution</code> instance. This means that <code>sampler sprinkler</code> does not type check and gives the type error: </p> <pre><code>No instance for (MonadMeasure SamplerIO)\n</code></pre> <p>This is to be expected. <code>SamplerIO</code> has no instance for <code>MonadFactor</code>. </p>"},{"location":"docs/usage/#weighted-m","title":"Weighted m","text":"<p>Summary of key info on <code>Weighted</code>:</p> <ul> <li><code>Weighted :: (Type -&gt; Type) -&gt; (Type -&gt; Type)</code></li> <li><code>instance MonadDistribution m =&gt; MonadMeasure (Weighted m)</code></li> <li><code>instance MonadFactor (Weighted m)</code></li> </ul> <pre><code>newtype Weighted m a = Weighted (StateT (Log Double) m a)\n</code></pre> <p>A key difference to <code>Enumerator</code> and <code>SamplerIO</code> is the kind of <code>Weighted</code>: it takes a type <code>m :: Type -&gt; Type</code> as an argument.</p>  <p><code>Weighted m</code> is isomorphic to:</p> <pre><code>Log Double -&gt; m (a, Log Double)\n</code></pre> <p>Some intuition for what this means comes from the <code>MonadFactor</code> instance:</p> <pre><code>instance Monad m =&gt; MonadFactor (Weighted m) where\n  score w = Weighted (modify (* w))\n</code></pre> <p>So if we write:</p> <pre><code>example :: MonadDistribution m =&gt; Weighted m Bool\nexample = do\n    x &lt;- bernoulli 0.5\n    score (if b then 1 else 0)\n    return x\n</code></pre> <p>then the result is that first, we draw a sample from a Bernoulli distribution from the underlying distribution <code>m</code>, and then multiply the state (which is a <code>Log Double</code>) by a number which depends on that sample. For convenience, we write <code>condition b = score (if b then 1 else 0)</code>. </p> <p>To unpack from <code>Weighted m a</code>, we use:</p> <pre><code>weighted :: Weighted m a -&gt; m (a, Log Double)\nweighted (Weighted m) = runStateT m 1\n</code></pre> <p><code>Weighted m</code> is not an instance of <code>MonadDistribution</code>, but only as instance of <code>MonadFactor</code> (and that, only when <code>m</code> is an instance of <code>Monad</code>). However, since <code>StateT</code> is a monad transformer, there is a function <code>lift :: m Double -&gt; Weighted m Double</code>.</p> <p>So if we take a <code>MonadDistribution</code> instance like <code>SamplerIO</code>, then <code>Weighted SamplerIO</code> is an instance of both <code>MonadDistribution</code> and <code>MonadFactor</code>. Which means it is an instance of <code>MonadMeasure</code>. </p> <p>So we can successfully write <code>(sampler . weighted) sprinkler</code> and get a program of type <code>IO (Bool, Log Double)</code>. When run, this will draw a sample from <code>sprinkler</code> along with an unnormalized density for that sample.</p> <p>It's worth stopping here to remark on what's going on. What has happened is that the <code>m</code> in <code>forall m. MonadMeasure m =&gt; m Bool</code> has been instantiated as <code>Weighted SamplerIO</code>. This is an example of how the interpreters for inference can be composed in modular ways.</p> <p>Finally, there's a function </p> <pre><code>hoist :: (forall x. m x -&gt; n x) -&gt; Weighted m a -&gt; Weighted n a\n</code></pre> <p>This takes a natural transformation <code>m ~&gt; n</code> and lifts it into a natural transformation <code>Weighted m ~&gt; Weighted n</code>. Most of the inference transformers have an analogous <code>hoist</code> function.</p>"},{"location":"docs/usage/#population","title":"Population","text":"<p>Summary of key info on <code>Population</code>:</p> <ul> <li><code>Population :: (Type -&gt; Type) -&gt; (Type -&gt; Type)</code></li> <li><code>instance MonadDistribution m =&gt; instance MonadDistribution (Population m)</code></li> <li><code>instance MonadFactor m =&gt; instance MonadFactor (Population m)</code></li> </ul> <pre><code>newtype Population m a = Population (Weighted (ListT m) a)\n</code></pre> <p>So:</p> <pre><code>Population m a ~ m [Log Double -&gt; (a, Log Double)]\n</code></pre> <p>Note that while <code>ListT</code> isn't in general a valid monad transformer, we're not requiring it to be one here.</p> <p><code>Population</code> is used to represent a collection of particles (in the statistical sense), along with their weights. </p> <p>There are several useful functions associated with it:</p> <pre><code>spawn :: Monad m =&gt; Int -&gt; Population m ()\nspawn n = fromWeightedList $ pure $ replicate n ((), 1 / fromIntegral n)\n</code></pre> <p><code>spawn</code> spawns new particles. As an example:</p> <pre><code>enumerator $ population (spawn 2)\n</code></pre> <p>gives</p> <pre><code>[([((),0.5),((),0.5)],1.0)]\n</code></pre> <p>Observe how here we have interpreted <code>(spawn 2)</code> as of type <code>Population Enumerator ()</code>. </p> <p><code>resampleGeneric</code> takes a function to probabilistically select a set of indices from a vector, and makes a new population by selecting those indices. </p> <pre><code>resampleGeneric ::\n  MonadDistribution m =&gt;\n    (V.Vector Double -&gt; m [Int]) -&gt;\n    Population m a -&gt;\n    Population m a\n</code></pre> <p><code>pushEvidence</code>, to quote the API docs, \"normalizes the weights in the population, while at the same time incorporating the sum of the weights as a score in m.\"</p> <pre><code>pushEvidence ::\n  MonadFactor m =&gt;\n  Population m a -&gt;\n  Population m a\n</code></pre> <p>In other words, <code>pushEvidence</code> takes a <code>Population m a</code> where <code>m</code> is a <code>MonadFactor</code> instance. It takes the sum of the weights, divides the weights by it, and then factors by the sum in <code>m</code>.</p>"},{"location":"docs/usage/#sequential","title":"Sequential","text":"<p>Summary of key info on <code>Sequential</code>:</p> <ul> <li><code>Sequential :: (Type -&gt; Type) -&gt; (Type -&gt; Type)</code></li> <li><code>instance MonadDistribution m =&gt; instance MonadDistribution (Sequential m)</code></li> <li><code>instance MonadFactor m =&gt; instance MonadFactor (Sequential m)</code></li> </ul> <pre><code>newtype Sequential m a = \n    Sequential {runSequential :: Coroutine (Await ()) m a}\n</code></pre> <p>This is a wrapper for the <code>Coroutine</code> type applied to the <code>Await</code> constructor from <code>Control.Monad.Coroutine</code>, which is defined thus:</p> <pre><code>newtype Coroutine s m r = Coroutine {\n   resume :: m (Either (s (Coroutine s m r)) r)\n   }\n\nnewtype Await x y = Await (x -&gt; y)\n</code></pre> <p>Unpacking that:</p> <pre><code>Sequential m a ~ m (Either (() -&gt; Sequential m a) a)\n</code></pre> <p>As usual, <code>m</code> is going to be some other probability monad, so understand <code>Sequential m a</code> as representing a program which, after making a random choice or doing conditioning, we either obtain an <code>a</code> value, or a paused computation, which when resumed gets us back to a new <code>Sequential m a</code>.</p> <p>(For more on coroutines, see the final article in: https://themonadreader.files.wordpress.com/2011/10/issue19.pdf.)</p> <p>The monad instance for coroutines is as follows:</p> <pre><code>instance (Functor s, Monad m) =&gt; Monad (Coroutine s m) where\n   return = pure\n   t &gt;&gt;= f = Coroutine (resume t &gt;&gt;= apply f)\n      where apply fc (Right x) = resume (fc x)\n            apply fc (Left s) = return (Left (fmap (&gt;&gt;= fc) s))\n</code></pre> <p>The <code>MonadDistribution</code> instance follows from <code>lift : m a -&gt; Coroutine (Await ()) m a</code>, defined as:</p> <pre><code>instance Functor s =&gt; MonadTrans (Coroutine s) where\n   lift = Coroutine . liftM Right\n</code></pre> <p>The <code>MonadFactor</code> instance has less trivial content:</p> <pre><code>-- | Execution is 'suspend'ed after each 'score'.\ninstance MonadFactor m =&gt; MonadFactor (Sequential m) where\n  score w = lift (score w) &gt;&gt; suspend\n</code></pre> <p>First you take a <code>score</code> in the underlying <code>MonadFactor</code> instance, and then you <code>suspend</code>, which means:</p> <pre><code>-- | A point where the computation is paused.\nsuspend :: Monad m =&gt; Sequential m ()\nsuspend = Sequential (Coroutine (return (Left (Await return))))\n</code></pre>  <p>We can move to the next suspension point with:</p> <pre><code>advance :: Monad m =&gt; Sequential m a -&gt; Sequential m a\nadvance = Sequential . bounce extract . runSequential\n</code></pre> <p>and move through all with:</p> <pre><code>-- | Remove the remaining suspension points.\nfinish :: Monad m =&gt; Sequential m a -&gt; m a\nfinish = pogoStick extract . runSequential\n</code></pre> <p>But most importantly, we can apply a natural transformation over the underlying monad <code>m</code> to only the current suspension.</p> <pre><code>hoistFirst :: (forall x. m x -&gt; m x) -&gt; Sequential m a -&gt; Sequential m a\nhoistFirst f = Sequential . Coroutine . f . resume . runSequential\n</code></pre> <p>When <code>m</code> is <code>Population n</code> for some other <code>n</code>, then <code>resampleGeneric</code> gives us one example of the natural transformation we want. In other words, operating in <code>Sequential (Population n)</code> works, and not only works but does something statistically interesting: particle filtering (aka SMC).</p> <p>Note: the running of <code>Sequential</code>, i.e. getting from <code>Sequential m a</code> to <code>m a</code> is surprisingly subtle, and there are many incorrect ways to do it, such as plain folds of the recursive structure. These can result in a semantics in which the transformation gets applied an exponentially large number of times.</p>"},{"location":"docs/usage/#density","title":"Density","text":"<p>Summary of key info on <code>Density</code>:</p> <ul> <li><code>Density :: (Type -&gt; Type) -&gt; (Type -&gt; Type)</code></li> <li><code>instance MonadDistribution (Density m)</code></li> <li>No instance for <code>MonadFactor</code></li> </ul> <p>A trace of a program of type <code>MonadDistribution m =&gt; m a</code> is an execution of the program, so a choice for each of the random values. Recall that <code>random</code> underlies all of the random values in a program, so a trace for a program is fully specified by a list of <code>Double</code>s, giving the value of each call to <code>random</code>.</p> <p>With this in mind, a <code>Density m a</code> is an interpretation of a probabilistic program as a function from a trace to the density of that execution of the program.</p> <p>Monad-bayes offers two implementations, in <code>Control.Monad.Bayes.Density.State</code> and <code>Control.Monad.Bayes.Density.Free</code>. The first is slow but easy to understand, the second is more sophisticated, but faster.</p> <p>The former is relatively straightforward: the <code>MonadDistribution</code> instance implements <code>random</code> as <code>get</code>ting the trace (using <code>get</code> from <code>MonadState</code>), using (and removing) the first element (<code>put</code> from <code>MonadState</code>), and writing that element to the output (using <code>tell</code> from <code>MonadWriter</code>). If the trace is empty, the <code>random</code> from the underlying monad is used, but the result is still written with <code>tell</code>.</p> <p>The latter is best understood if you're familiar with the standard use of a free monad to construct a domain specific language. For probability in particular, see this blog post. Here's the definition:</p> <pre><code>newtype SamF a = Random (Double -&gt; a)\nnewtype Density m a = \n    Density {density :: FT SamF m a}\n\ninstance Monad m =&gt; MonadDistribution (Density m) where\n  random = Density $ liftF (Random id)\n</code></pre> <p>The monad-bayes implementation uses a more efficient implementation of <code>FreeT</code>, namely <code>FT</code> from the <code>free</code> package, known as the Church transformed Free monad. This is a technique explained in https://begriffs.com/posts/2016-02-04-difference-lists-and-codennsity.html. But that only changes the operational semantics - performance aside, it works just the same as the standard <code>FreeT</code> datatype. </p> <p>If you unpack the definition, you get:</p> <pre><code>Density m a ~ m (Either a (Double -&gt; (Density m a)))\n</code></pre> <p>Since <code>FreeT</code> is a transformer, we can use <code>lift</code> to get a <code>MonadDistribution</code> instance.</p> <p><code>density</code> is then defined using the folding pattern <code>iterFT</code>, which interprets <code>SamF</code> in the appropriate way:</p> <pre><code>density :: MonadDistribution m =&gt; [Double] -&gt; Density m a -&gt; m (a, [Double])\ndensity randomness (Density m) =\n  runWriterT $ evalStateT (iterTM f $ hoistFT lift m) randomness\n  where\n    f (Random k) = do\n      -- This block runs in StateT [Double] (WriterT [Double]) m.\n      -- StateT propagates consumed randomness while WriterT records\n      -- randomness used, whether old or new.\n      xs &lt;- get\n      x &lt;- case xs of\n        [] -&gt; random\n        y : ys -&gt; put ys &gt;&gt; return y\n      tell [x]\n      k x\n</code></pre> <p>This takes a list of <code>Double</code>s (a representation of a trace), and a probabilistic program like <code>example</code>, and gives back a <code>SamplerIO (Bool, [Double])</code>. At each call to <code>random</code> in <code>example</code>, the next double in the list is used. If the list of doubles runs out, calls are made to <code>random</code> using the underlying monad.</p>"},{"location":"docs/usage/#traced","title":"Traced","text":"<p>Summary of key info on <code>Traced</code>:</p> <ul> <li><code>Traced :: (Type -&gt; Type) -&gt; (Type -&gt; Type)</code></li> <li><code>instance MonadDistribution m =&gt; MonadDistribution (Traced m)</code></li> <li><code>instance MonadFactor m =&gt; MonadFactor (Traced m)</code></li> </ul> <p><code>Traced m</code> is actually several related interpretations, each built on top of <code>Density</code>. These range in complexity.</p>  <p>The reason traces are relevant here is that monad-bayes implements a version of Markov Chain Monte Carlo (MCMC) that operates on arbitrary probabilistic programs often referred to as trace MCMC. The idea is that the MCMC chain takes place on traces of the program. A step constitutes a change to this trace, i.e. to the list of <code>Double</code>s. For instance, the algorithm for an MH step goes as follows:</p> <ul> <li>propose a new trace by randomly redrawing a single <code>Double</code> in the trace</li> <li>accept or reject with the MH criterion</li> </ul> <p>It's convenient to specify a trace not just as a <code>[Double]</code> but also with the resulting output, and the density of that output. This is what monad-bayes does:</p> <pre><code>data Trace a = Trace\n  { \n    variables :: [Double],\n    output :: a,\n    density :: Log Double\n  }\n</code></pre> <p>We also need a specification of the probabilistic program in question, free of any particular interpretation. That is precisely what <code>Density</code> is for. </p> <p>The simplest version of <code>Traced</code> is in <code>Control.Monad.Bayes.Traced.Basic</code></p> <pre><code>Traced m a ~ (Density Identity a, Log Double), m (Trace a))\n</code></pre> <p>A <code>Traced</code> interpretation of a model is a particular run of the model with its corresponding probability, alongside a distribution over <code>Trace</code> info, which records: the value of each call to <code>random</code>, the value of the final output, and the density of this program trace.</p> <p>This machinery allows us to implement MCMC (see inference methods below for details). </p>"},{"location":"docs/usage/#integrator","title":"Integrator","text":"<p>Summary of key info:</p> <ul> <li><code>Integrator :: Type -&gt; Type</code></li> <li><code>instance MonadDistribution Integrator</code></li> </ul> <p><code>Integrator</code> is in <code>Control.Monad.Bayes.Integrator</code>, defined as follows:</p> <pre><code>newtype Integrator a = Integrator {getCont :: Cont Double a}\n</code></pre> <p>This <code>MonadDistribution</code> instance interprets a probabilistic program as a numerical integrator. For a nice explanation, see this blog post.</p> <p><code>Integrator a</code> is isomorphic to <code>(a -&gt; Double) -&gt; Double</code>.  A program <code>model</code> of type <code>Integrator a</code> will take a function <code>f</code> and calculate \\(E_{p}[f] = \\int f(x)*p(x)\\) where \\(p\\) is the density of <code>model</code>. </p> <p>The integral for the expectation is performed by quadrature, using the tanh-sinh approach. For example, <code>random :: Integrator Double</code> is the program which takes a function <code>f</code> and integrates <code>f</code> over the \\((0,1)\\) range.</p> <p>We can calculate the probability for an interval $(a,b)4 of any model of type <code>Integrator Double</code> by setting <code>f</code> to be the function that returns \\(1\\) for that range, else \\(0\\). Similarly for the CDF, MGF and so on.</p>"},{"location":"docs/usage/#inference-methods-under-the-hood","title":"Inference methods under the hood","text":""},{"location":"docs/usage/#exact-inference","title":"Exact inference","text":"<p>Exact inference is nothing more than the use of the <code>Enumerator</code> instance of <code>MonadMeasure</code>. It should be noted that this is not a particularly efficient or clever version of exact inference.</p> <p>For example, consider:</p> <pre><code>example = replicateM 100 $ do\n  x &lt;- bernoulli 0.5\n  condition x\n  return x\n</code></pre> <p>Doing <code>enumerator example</code> will create a list of \\(2^{100}\\) entries, all but one of which have \\(0\\) mass. (See below for a way to perform this inference efficiently). </p> <p>The main purpose of <code>Enumerator</code> is didactic, as a way to understand simple discrete distributions in full. In addition, you can use it in concert with transformers like <code>Weighted</code>, to get a sense of how they work. For example, consider:</p> <pre><code>example = do\n  x &lt;- bernoulli 0.5\n  condition x\n  return x\n</code></pre> <p><code>(enumerator . weighted) example</code> gives <code>[((False,0.0),0.5),((True,1.0),0.5)]</code>. This is quite edifying for understanding <code>(sampler . weighted) example</code>. What it says is that there are precisely two ways the program will run, each with equal probability: either you get <code>False</code> with weight <code>0.0</code> or <code>True</code> with weight <code>1.0</code>. </p>"},{"location":"docs/usage/#quadrature","title":"Quadrature","text":"<p>As described on the section on <code>Integrator</code>, we can interpret our probabilistic program of type <code>MonadDistribution m =&gt; m a</code> as having concrete type <code>Integrator a</code>. This views our program as an integrator, allowing us to calculate expectations, probabilities and so on via quadrature (i.e. numerical approximation of an integral).</p> <p>This can also handle programs of type <code>MonadMeasure m =&gt; m a</code>, that is, programs with <code>factor</code> statements. For these cases, a function <code>normalize :: Weighted Integrator a -&gt; Integrator a</code> is employed. For example, </p> <pre><code>model :: MonadMeasure m =&gt; m Double\nmodel = do\n  var &lt;- gamma 1 1\n  n &lt;- normal 0 (sqrt var)\n  condition (n &gt; 0)\n  return var\n</code></pre> <p>is really an unnormalized measure, rather than a probability distribution. <code>normalize</code> views it as of type <code>Weighted Integrator Double</code>, which is isomorphic to <code>(Double -&gt; (Double, Log Double) -&gt; Double)</code>. This can be used to compute the normalization constant, and divide the integrator's output by it, all within <code>Integrator</code>. </p>"},{"location":"docs/usage/#independent-forward-sampling","title":"Independent forward sampling","text":"<p>For any program of type <code>p = MonadDistribution m =&gt; m a</code>, we may do <code>sampler p</code> or <code>runST $ sampleSTfixed p</code>. Note that if there are any calls to <code>factor</code> in the program, then it cannot have type <code>MonadDistribution m</code>. </p>"},{"location":"docs/usage/#independent-weighted-sampling","title":"Independent weighted sampling","text":"<p>Consider </p> <pre><code>example :: MonadMeasure m =&gt; m Bool\nexample = do\n  x &lt;- bernoulli 0.5\n  condition x\n  return x\n</code></pre> <p><code>(weighted . sampler) example :: IO (Bool, Log Double)</code> returns a tuple of a truth value and a probability mass (or more generally density). How does this work? Types are clarifying:</p> <pre><code>run = \n  (sampler :: SamplerIO (a, Log Double) -&gt; IO (a, Log Double) )\n  . (weighted ::  Weighted SamplerIO a -&gt; SamplerIO (a, Log Double)\n</code></pre> <p>In other words, the program is being interpreted in the <code>Weighted SamplerIO</code> instance of <code>MonadMeasure</code>.</p>"},{"location":"docs/usage/#metropolis-hastings-mcmc","title":"Metropolis Hastings MCMC","text":"<p>The version of MCMC in monad-bayes performs its random walk on program traces of type <code>Trace a</code>. The motivation for doing this is that any probabilistic program can then be used with MCMC entirely automatically.</p> <p>A single step in this chain (in Metropolis Hasting MCMC) looks like this:</p> <pre><code>mhTrans :: MonadDistribution m =&gt; (Weighted (State.Density m)) a -&gt; Trace a -&gt; m (Trace a)\nmhTrans m t@Trace {variables = us, probDensity = p} = do\n  let n = length us\n  us' &lt;- do\n    i &lt;- discrete $ discreteUniformAB 0 (n - 1)\n    u' &lt;- random\n    case splitAt i us of\n      (xs, _ : ys) -&gt; return $ xs ++ (u' : ys)\n      _ -&gt; error \"impossible\"\n  ((b, q), vs) &lt;- State.density (weighted m) us'\n  let ratio = (exp . ln) $ min 1 (q * fromIntegral n / (p * fromIntegral (length vs)))\n  accept &lt;- bernoulli ratio\n  return $ if accept then Trace vs b q else t\n</code></pre> <p>Our probabilistic program is interpreted in the type <code>Weighted (Density m) a</code>, which is an instance of <code>MonadMeasure</code>. We use this to define our kernel on traces. We begin by perturbing the list of doubles contained in the trace by selecting a random position in the list and resampling there. We could do this proposal in a variety of ways, but here, we do so by choosing a double from the list at random and resampling it (hence, single site trace MCMC). We then run the program on this new list of doubles; <code>((b,q), vs)</code> is the outcome, probability, and result of all calls to <code>random</code>, respectively (recalling that the list of doubles may be shorter than the number of calls to <code>random</code>). The value of these is probabilistic in the underlying monad <code>m</code>. We then use the MH criterion to decide whether to accept the new list of doubles as our trace.</p> <p>MH is then easily defined as taking steps with this kernel, in the usual fashion. Note that it works for any probabilistic program whatsoever.</p> <p>Warning: the default proposal is single site, meaning that you change one random number in the trace at a time. As a result, the proposal may not be ergodic for models with hard constraints. As a simple example, suppose that you're doing a random walk, and trying to get from a trace corresponding to the output <code>(True, True)</code> to a trace corresponding to <code>(False, False)</code>. But if <code>(False, True)</code> and <code>(True, False)</code> have no probability, you have no hope of getting there. Don't expect MCMC to be efficient without designing your own proposal, or even correct when the proposal is not ergodic.</p>"},{"location":"docs/usage/#sequential-importance-sampling","title":"Sequential Importance Sampling","text":"<p>This is provided by </p> <pre><code>sequentially ::\n  Monad m =&gt;\n  -- | transformation\n  (forall x. m x -&gt; m x) -&gt;\n  -- | number of time steps\n  Int -&gt;\n  Sequential m a -&gt;\n  m a\nsequentially f k = finish . composeCopies k (advance . hoistFirst f)\n</code></pre> <p>in <code>Control.Monad.Bayes.Sequential.Coroutine</code>. You provide a natural transformation in the underlying monad <code>m</code>, and <code>sequentially</code> applies that natural transformation at each point of conditioning in your program. The main use case is in defining <code>smc</code>, below, but here is a nice didactic use case:</p> <p>Consider the program:</p> <pre><code>example = replicateM 100 $ do\n  x &lt;- bernoulli 0.5\n  condition x\n  return x\n</code></pre> <p>Naive enumeration, as in <code>enumerator example</code> is enormously and needlessly inefficient, because it will create a \\(2^{100}\\) size list of possible values. What we'd like to do is to throw away values of <code>x</code> that are <code>False</code> at each condition statement, rather than carrying them along forever.</p> <p>Suppose we have a function <code>removeZeros :: Enumerator a -&gt; Enumerator a</code>, which removes values of the distribution with \\(0\\) mass from <code>Enumerator</code>. We can then write <code>enumerator $ sequentially removeZeros 100 $ model</code> to run <code>removeZeros</code> at each of the 100 <code>condition</code> statements, making the algorithm run quickly. </p>"},{"location":"docs/usage/#sequential-monte-carlo","title":"Sequential Monte Carlo","text":"<p>Sequential importance resampling works by doing <code>sequentially</code> with a resampler of your choice, such as <code>resampleMultinomial</code>, after first spawning a set of <code>n</code> particles.</p> <pre><code>smc ::\n  Monad m =&gt;\n  -- | resampler\n  (forall x. Population m x -&gt; Population m x) -&gt;\n  -- | number of timesteps\n  Int -&gt;\n  -- | population size\n  Int -&gt;\n  -- | model\n  Sequential (Population m) a -&gt;\n  Population m a\nsmc resampler k n = sequentially resampler k . Seq.hoistFirst (spawn n &gt;&gt;)\n</code></pre>"},{"location":"docs/usage/#particle-marginal-metropolis-hastings","title":"Particle Marginal Metropolis Hastings","text":"<p>Quoting the monad-bayes paper:</p> <p>\"PMMH is only applicable to models with a specific structure, namely the probabilistic program needs to decompose to a prior over the global parameters <code>m param</code> and the rest of the model <code>param -&gt; m a</code>. Combining these using &gt;&gt;= would yield the complete model of type <code>m a</code>.\"</p> <p>\"The idea is to do MH on the parameters of the model. Recall that for MH we need to compute the likelihood for the particular values of parameters but that involves integrating over the remaining random variables in the model which is intractable. Fortunately to obtain valid MH it is sufficient to have an unbiased estimator for the likelihood which is produced by a single sample from <code>Weighted</code>. MH with such an estimator is referred to as pseudo-marginal MH. If instead of taking a single weight from <code>Weighted</code> we take the sum of weights from <code>Population</code> we obtain an unbiased estimator with lower variance. In particular if such a <code>Population</code> is a result of smc the resulting algorithm is known as PMMH.\"</p> <p>Because of the modularity of monad-bayes, the implementation is remarkably simple, and directly linked to the algorithm:</p> <pre><code>pmmh mcmcConf smcConf param model =\n  mcmc\n    mcmcConf\n    ( param\n        &gt;&gt;= population\n          . pushEvidence\n          . Pop.hoist lift\n          . smc smcConf\n          . model\n    )\n</code></pre> <p>There's a lot to unpack here. Here's the definition with more types. To shorten the signatures, the synonyms: <code>T = Traced, S = Sequential, P = Population</code> are used:</p> <pre><code>pmmh ::\n  MonadDistribution m =&gt;\n  MCMCConfig -&gt;\n  SMCConfig (Weighted m) -&gt;\n  Traced (Weighted m) a1 -&gt;\n  (a1 -&gt; Sequential (Population (Weighted m)) a2) -&gt;\n  m [[(a2, Log Double)]]\npmmh mcmcConf smcConf param model =\n  (mcmc mcmcConf :: T m [(a, Log Double)] -&gt; m [[(a, Log Double)]])\n  ((param :: T m b) &gt;&gt;= \n      (population :: P (T m) a -&gt; T m [(a, Log Double)]) \n      . (pushEvidence :: P (T m) a -&gt; P (T m) a) \n      . Pop.hoist (lift :: forall x. m x -&gt; T m x) \n      . (smc smcConf :: S (P m) a -&gt; P m a) \n      . (model :: b -&gt; S (P m) a))\n</code></pre> <p>(Note that this uses the version of <code>mcmc</code> that uses the <code>Traced</code> representation from <code>Control.Monad.Bayes.Traced.Static</code>.)</p> <p>To understand this, note that the outer algorithm is just <code>mcmc</code>. But the probabilistic program that we pass to <code>mcmc</code> does the following: run <code>param</code> to get values for the parameters and then pass these to <code>model</code>. Then run <code>n</code> steps of SMC with <code>k</code> particles. Then lift the underlying monad <code>m</code> into <code>Traced m</code>. Then calculate the sum of the weights of the particles and <code>factor</code> on this (this is what <code>pushEvidence</code> does). This <code>factor</code> takes place in <code>Traced m</code>, so it is \"visible\" to <code>mcmc</code>.</p>"},{"location":"docs/usage/#resample-move-sequential-monte-carlo","title":"Resample-Move Sequential Monte Carlo","text":"<p>The paper introducing monad-bayes has this to say about resample-move SMC:</p> <p>\"A common problem with particle filters is that of particle degeneracy, where after resampling many particles are the same, effectively reducing the sample size. One way to ameliorate this problem is to introduce rejuvenation moves, where after each resampling we apply a number of MCMC transitions to each particle independently, thus spreading them around the space. If we use an MCMC kernel that preserves the target distribution at a given step, the resulting algorithm is correct\"</p> <p>monad-bayes provides three versions of RMSMC, each of which uses one of the three <code>Traced</code> implementations respectively. Here is the simplest, which I have annotated with types. To shorten the signatures, the synonyms: <code>T = Traced, S = Sequential, P = Population</code> are used:</p> <pre><code>rmsmcBasic ::\n  MonadDistribution m =&gt;\n  MCMCConfig -&gt;\n  SMCConfig m -&gt;\n  -- | model\n  S (T (P m)) a -&gt;\n  P m a\nrmsmc (MCMCConfig {..}) (SMCConfig {..}) =\n  (TrBas.marginal :: T (P m) a -&gt; P m a )\n  . sequentially \n      (\n      (composeCopies numMCMCSteps TrBas.mhStep :: T (P m) a -&gt; T (P m) a )\n      . TrBas.hoist (resampleSystematic :: P m a -&gt; P m a ) ) \n      numSteps\n  . (S.hoistFirst (TrBas.hoist (spawn numParticles &gt;&gt;)) :: S (T (P m)) a -&gt; S (T (P m)) a ))\n</code></pre> <p>What is this doing? Recall that <code>S m a</code> represents an <code>m</code> of coroutines over <code>a</code>. Recall that <code>Traced m a</code> represents an <code>m</code> of  traced computations of <code>a</code>. Recall that <code>P m a</code> represents an <code>m</code> of a list of <code>a</code>s.</p> <p>This means that an <code>S (T (P m)) a</code> is a program \"interpreted as a population of traced coroutines\". The paper adds that this \"allows us to apply MH transitions to partially executed coroutines, which is exactly what we require for the rejuvenation steps.\"</p> <p>So the algorithm works by creating <code>n</code> particles, and at each of the first <code>k</code> calls to <code>factor</code>, first resampling the population and then for each particle in the population, doing an MH-MCMC walk for <code>t</code> steps to update it. </p>"},{"location":"docs/usage/#sequential-monte-carlo-squared","title":"Sequential Monte Carlo Squared","text":"<p>This combines RMSMC and PMMH. That is, it is RMSMC, but for the MCMC rejuvenation procedure, PMMH is used instead of MH.</p> <p>There is one slight complication here, related to the fact that the MTL style effect system approach requires newtypes when more than one of a given effect appears in a stack, in order to differentiate them.</p>"}]}